{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "montevideo-bus-forecast.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8VQzv6FAf3Tbyeuvq2tJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guzmanlopez/montevideo-bus-forecast/blob/main/montevideo_bus_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVYlc4sTvqrd"
      },
      "source": [
        "# Curso Aprendizaje Automático para Datos en Grafos\n",
        "\n",
        "**Docente:** Prof. Gonzalo Mateos (Universidad de Rochester, EEUU).\n",
        "\n",
        "**Docente invitado:** Fernando Gama (Universidad de California Berkeley, EEUU).\n",
        "\n",
        "**Otros docentes:** Marcelo Fiori y Federico La Rocca.\n",
        "\n",
        "**Fechas:** 01/02/2021 al 04/02/2021 y 11/02/2021.\n",
        "\n",
        "**Web:** [Página principal del curso en plataforma Eva](https://eva.fing.edu.uy/course/view.php?id=1484)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Proyecto final del curso\n",
        "\n",
        "### Predicción del flujo de pasajeros en las paradas de ómnibus del Sistema de Transporte Metropolitano (STM) de Montevideo\n",
        "\n",
        "**Estudiante:** Guzmán López\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg33_xulwVV4"
      },
      "source": [
        "Montar drive para descargar el repositorio del proyecto desde GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovbhaZpeOp_X",
        "outputId": "a40e1c48-d4a6-431f-8cfe-f3a6c0243a4a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "%cd gdrive/My Drive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEgu_4Gse47K",
        "outputId": "cdcad257-39ce-468d-ad97-c9891435a04c"
      },
      "source": [
        "!git clone https://github.com/guzmanlopez/montevideo-bus-forecast.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'montevideo-bus-forecast' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TTpQv_WQn9X",
        "outputId": "586e2586-427f-4e03-a06a-8cd5e2e2fe8f"
      },
      "source": [
        "%cd montevideo-bus-forecast/\n",
        "!git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/montevideo-bus-forecast\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 8 (delta 6), reused 8 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n",
            "From https://github.com/guzmanlopez/montevideo-bus-forecast\n",
            "   053ddfa..e138f90  main       -> origin/main\n",
            "Updating 053ddfa..e138f90\n",
            "Fast-forward\n",
            " README.md                    | 21 \u001b[32m+++++++++++++++++++++\u001b[m\n",
            " src/preparation/constants.py |  4 \u001b[32m+\u001b[m\u001b[31m---\u001b[m\n",
            " 2 files changed, 22 insertions(+), 3 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N659Dc1wf2k"
      },
      "source": [
        "Instalar todas las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4e2tLzBcbfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bae037-a55c-4e23-a4e9-325196b37bb2"
      },
      "source": [
        "# Install required packages\n",
        "!pip install pandas\n",
        "!pip install geopandas\n",
        "!pip install networkx\n",
        "!pip install numpy\n",
        "!pip install altair\n",
        "!pip install requests\n",
        "!pip install typer\n",
        "!pip install pretty-errors\n",
        "!pip install matplotlib\n",
        "!pip install sklearn\n",
        "\n",
        "# Instalar PyTorch\n",
        "!pip install torch==1.8.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Instalar PyTorch Geometric\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Instalar PyTorch Geometric Temporal\n",
        "!pip install torch-geometric-temporal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/bf/e9cefb69d39155d122b6ddca53893b61535fa6ffdad70bf5ef708977f53f/geopandas-0.9.0-py2.py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Collecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/72/d52e9ca81caef056062d71991b0e9b1d16af042245627c5d0e4916a36c4f/pyproj-3.0.1-cp37-cp37m-manylinux2010_x86_64.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 47.0MB/s \n",
            "\u001b[?25hCollecting fiona>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/2a/404b22883298a3efe9c6ef8d67acbf2c38443fa366ee9cd4cd34e17626ea/Fiona-1.8.19-cp37-cp37m-manylinux1_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 170kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj>=2.2.0->geopandas) (2020.12.5)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (20.3.0)\n",
            "Installing collected packages: pyproj, munch, cligj, click-plugins, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.19 geopandas-0.9.0 munch-2.5.0 pyproj-3.0.1\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.7/dist-packages (4.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair) (2.11.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair) (0.11.1)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from altair) (1.1.5)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from altair) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->altair) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Collecting typer\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer) (7.1.2)\n",
            "Installing collected packages: typer\n",
            "Successfully installed typer-0.3.2\n",
            "Collecting pretty-errors\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/ea/7b0ac735ed1a3b90f723cc55a5a273810dfa6daef31a546ed289a1d15f19/pretty_errors-1.2.19-py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama, pretty-errors\n",
            "Successfully installed colorama-0.4.4 pretty-errors-1.2.19\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.8.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (763.5MB)\n",
            "\u001b[K     |████████████████████████████████| 763.5MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.8.0+cu101 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.8.0+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bk7yNZFvoIm"
      },
      "source": [
        "Descargar y procesar datos hasta obtener finalmente el grafo que usaremos para modelar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0rwP5mXzws3"
      },
      "source": [
        "# Note: this file can take some time to be downloaded because is 2.5 GB\n",
        "%run src/preparation/download_stm_bus_data.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWWqMHq01uRG"
      },
      "source": [
        "%run src/preparation/download_bus_stops.py\n",
        "%run src/preparation/download_bus_tracks.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLt0KC3Xeiwu"
      },
      "source": [
        "%run src/processing/process_stm_bus_data.py\n",
        "%run src/processing/build_bus_line_tracks_and_stops.py\n",
        "%run src/processing/sort_bus_stops_along_bus_track.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW1tfRwlz7dB"
      },
      "source": [
        "%run src/processing/build_adyacency_matrix.py\n",
        "%run src/processing/build_graph.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW3K8mHLxQDv"
      },
      "source": [
        "# Análisis Exploratorio de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hw0CabxOjZ2"
      },
      "source": [
        "import geopandas as gpd\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from notebooks.eda.plots import (\n",
        "    plot_boardings_by_day_name,\n",
        "    plot_boardings_by_hour_and_day_name,\n",
        "    plot_boardings_by_time,\n",
        ")\n",
        "from src.preparation.constants import BUFFER, BUS_LINES, CRS, DAY_NAME_MAPPING, PROCESSED_FILE\n",
        "from src.preparation.utils import (\n",
        "    load_pickle_file,\n",
        "    load_spatial_data,\n",
        "    load_stm_bus_data,\n",
        "    load_stm_bus_line_track,\n",
        "    load_stm_bus_stops,\n",
        "    save_pickle_file,\n",
        ")\n",
        "from src.processing.process_stm_bus_data import pre_process_data\n",
        "from src.processing.utils import (\n",
        "    build_adyacency_matrix,\n",
        "    build_bus_line_tracks_and_stops,\n",
        "    fix_bus_stop_order,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZn9b4FZyS0x"
      },
      "source": [
        "# Load data and pre-process data\n",
        "df = pre_process_data(load_stm_bus_data())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHjq36UyyX0v"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlCwpR6ryh3E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDK3hq6LycTf"
      },
      "source": [
        "df_hourly = df.groupby([pd.Grouper(freq=\"1H\")])[\"cantidad_pasajeros\"].sum().reset_index()\n",
        "plot_boardings_by_time(df_hourly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3noG9fY1yhYJ"
      },
      "source": [
        "# Daily sum of boardings and median by day name\n",
        "df_day_name = (\n",
        "    df.groupby([pd.Grouper(freq=\"1D\"), \"nombre_dia\"])[\"cantidad_pasajeros\"]\n",
        "    .sum()\n",
        "    .groupby([\"nombre_dia\"])\n",
        "    .median()\n",
        "    .reset_index()\n",
        ")\n",
        "plot_boardings_by_day_name(df_day_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCuUVe6yoHa"
      },
      "source": [
        "# Hourly sum of boardings and median by day name\n",
        "df_hourly_day_name = df_hourly.copy()\n",
        "df_hourly_day_name.set_index(\"fecha_evento\", inplace=True)\n",
        "df_hourly_day_name.loc[:, \"nombre_dia\"] = df_hourly_day_name.index.day_name()\n",
        "df_hourly_day_name.loc[:, \"nombre_dia\"].replace(DAY_NAME_MAPPING, inplace=True)\n",
        "df_hourly_day_name.loc[:, \"hora\"] = df_hourly_day_name.index.hour\n",
        "df_hourly_day_name = df_hourly_day_name.groupby([\"hora\", \"nombre_dia\"]).median().reset_index()\n",
        "\n",
        "plot_boardings_by_hour_and_day_name(df_hourly_day_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfNuV465ysSO"
      },
      "source": [
        "# Get top buses lines per day of the week\n",
        "df_weekly_by_day_name_and_line = (\n",
        "    df.groupby([pd.Grouper(freq=\"1D\"), \"nombre_dia\", \"dsc_linea\"])[\"cantidad_pasajeros\"]\n",
        "    .sum()\n",
        "    .groupby([\"dsc_linea\", \"nombre_dia\"])\n",
        "    .median()\n",
        "    .groupby(\"dsc_linea\")\n",
        "    .sum()\n",
        "    .sort_values(ascending=False)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "df_weekly_by_day_name_and_line[\"decile_rank\"] = pd.qcut(\n",
        "    df_weekly_by_day_name_and_line[\"cantidad_pasajeros\"], 10, labels=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I94BPoUcywnn"
      },
      "source": [
        "# Contribution of each decile\n",
        "df_decile_rank_prop = df_weekly_by_day_name_and_line.groupby(\"decile_rank\").sum().reset_index()\n",
        "df_decile_rank_prop[\"proportion\"] = (\n",
        "    df_decile_rank_prop[\"cantidad_pasajeros\"] / df_decile_rank_prop[\"cantidad_pasajeros\"].sum()\n",
        ")\n",
        "\n",
        "# Select bus lines from the 9th decile\n",
        "df_bus_lines = df_weekly_by_day_name_and_line.loc[\n",
        "    df_weekly_by_day_name_and_line[\"decile_rank\"] == 9, :\n",
        "]\n",
        "df_bus_lines = df_bus_lines.sort_values(\"cantidad_pasajeros\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBmfB7veQjos"
      },
      "source": [
        "# %% [markdown]\n",
        "# ## Build bus line tracks\n",
        "\n",
        "# %%\n",
        "# Load processed file\n",
        "df_proc = load_pickle_file(PROCESSED_FILE)\n",
        "\n",
        "# Load bus stops\n",
        "gdf_bus_stops = load_stm_bus_stops()\n",
        "\n",
        "# Load bus tracks\n",
        "gdf_bus_tracks = load_stm_bus_line_track()\n",
        "\n",
        "# %%\n",
        "# Read all bus stops by bus line from geojson files\n",
        "all_bus_stops = gpd.GeoDataFrame()\n",
        "for bus_line in BUS_LINES:\n",
        "    all_bus_stops = all_bus_stops.append(load_spatial_data(bus_line, type=\"bus_stop\"))\n",
        "all_bus_stops = all_bus_stops.set_crs(CRS)\n",
        "\n",
        "# Read all bus tracks by bus line from geojson files\n",
        "all_bus_tracks = gpd.GeoDataFrame()\n",
        "for bus_line in BUS_LINES:\n",
        "    df = load_spatial_data(bus_line, type=\"bus_line\")\n",
        "    df[\"line\"] = bus_line\n",
        "    all_bus_tracks = all_bus_tracks.append(df)\n",
        "all_bus_tracks = all_bus_tracks.set_crs(CRS)\n",
        "\n",
        "# %%\n",
        "# Get ordered bus stops and bus tracks from files\n",
        "all_bus_stops_ordered, all_bus_tracks_ordered = gpd.GeoDataFrame(), gpd.GeoDataFrame()\n",
        "\n",
        "for bus_line in BUS_LINES:\n",
        "    df_bus_stop_ordered = load_spatial_data(bus_line, type=\"bus_stop_ordered\")\n",
        "    all_bus_stops_ordered = all_bus_stops_ordered.append(df_bus_stop_ordered)\n",
        "\n",
        "    df_bus_track_ordered = load_spatial_data(bus_line, type=\"bus_track_ordered\")\n",
        "    df_bus_track_ordered[\"DESC_LINEA\"] = bus_line\n",
        "    all_bus_tracks_ordered = all_bus_tracks_ordered.append(df_bus_track_ordered)\n",
        "\n",
        "all_bus_stops_ordered = all_bus_stops_ordered.set_crs(CRS)\n",
        "all_bus_stops_ordered = all_bus_stops_ordered.astype({\"COD_UBIC_P\": \"int\"})\n",
        "all_bus_tracks_ordered = all_bus_tracks_ordered.set_crs(CRS)\n",
        "\n",
        "# %%\n",
        "# Fix order from origin\n",
        "for bus_line in BUS_LINES:\n",
        "    if bus_line == \"183\":\n",
        "        fix_bus_stop_order(bus_line, reorder=True)\n",
        "    elif bus_line != \"405\":\n",
        "        fix_bus_stop_order(bus_line)\n",
        "\n",
        "# %%\n",
        "# Check shared bus stops by lines\n",
        "shared_bus_stops = (\n",
        "    all_bus_stops_ordered.groupby([\"COD_UBIC_P\"])\n",
        "    .agg(lines=(\"DESC_LINEA\", \"|\".join), number_of_lines=(\"DESC_LINEA\", len))\n",
        "    .round(0)\n",
        "    .sort_values(\"COD_UBIC_P\", ascending=True)\n",
        "    .reset_index()\n",
        "    .astype({\"COD_UBIC_P\": int})\n",
        ")\n",
        "\n",
        "print(shared_bus_stops.loc[shared_bus_stops[\"number_of_lines\"] > 1, :][\"lines\"].unique())\n",
        "\n",
        "\n",
        "# %%\n",
        "# Get distances for shared bus stations\n",
        "shared = shared_bus_stops.loc[shared_bus_stops[\"number_of_lines\"] > 1, :][[\"COD_UBIC_P\", \"lines\"]]\n",
        "\n",
        "for bus_stop, bus_lines in zip(shared[\"COD_UBIC_P\"], shared[\"lines\"]):\n",
        "    bus_lines = bus_lines.split(\"|\")\n",
        "    for bus_line in bus_lines:\n",
        "        bus_stops_by_line = all_bus_stops_ordered.loc[\n",
        "            (all_bus_stops_ordered[\"DESC_LINEA\"] == bus_line) & (all_bus_stops_ordered[\"COD\"]), :\n",
        "        ]\n",
        "        bus_tracks_by_line = all_bus_tracks_ordered.loc[\n",
        "            all_bus_tracks_ordered[\"DESC_LINEA\"] == bus_line, :\n",
        "        ]\n",
        "\n",
        "# %%\n",
        "# Build adyacency matrix\n",
        "# df_adyacency_matrix, df_from_to_weight = build_adyacency_matrix(control=True)\n",
        "df_adyacency_matrix = pd.read_csv(\"data/processed/adyacency_matrix.csv\", index_col=0)\n",
        "df_adyacency_matrix.columns = df_adyacency_matrix.columns.astype(int)\n",
        "\n",
        "df_from_to_weight = pd.read_csv(\"data/processed/from_to_weight.csv\", index_col=0)\n",
        "\n",
        "# %%\n",
        "# Check adyacency matrix\n",
        "bus_stops_103 = all_bus_stops_ordered.loc[all_bus_stops_ordered[\"DESC_LINEA\"] == \"103\", :]\n",
        "bus_stops_list = bus_stops_103[\"COD_UBIC_P\"].unique()\n",
        "dist_between_stops = list()\n",
        "\n",
        "for i in range(0, (len(bus_stops_list) - 1)):\n",
        "    bus_stop_start = bus_stops_103.loc[i, \"COD_UBIC_P\"]\n",
        "    bus_stop_end = bus_stops_103.loc[(i + 1), \"COD_UBIC_P\"]\n",
        "    d = df_adyacency_matrix.loc[bus_stop_start, bus_stop_end]\n",
        "    dist_between_stops.append(d)\n",
        "\n",
        "print(dist_between_stops)\n",
        "\n",
        "\n",
        "# %%\n",
        "G = nx.from_pandas_edgelist(\n",
        "    df_from_to_weight, source=\"from\", target=\"to\", edge_attr=\"weight\", create_using=nx.DiGraph\n",
        ")\n",
        "G.name = \"Bus lines of Montevideo\"\n",
        "print(nx.info(G))\n",
        "\n",
        "# %%\n",
        "layout = nx.spring_layout(G)\n",
        "nx.draw(G, layout, with_labels=True)\n",
        "\n",
        "\n",
        "# %%\n",
        "# Build directed graph from A. matrix\n",
        "G = nx.from_pandas_adjacency(df_adyacency_matrix, create_using=nx.DiGraph)\n",
        "G.name = \"Graph of bus lines of Montevideo\"\n",
        "print(nx.info(G))\n",
        "\n",
        "# %%\n",
        "A = df_adyacency_matrix.values\n",
        "G = nx.from_numpy_array(A, parallel_edges=False, create_using=nx.DiGraph)\n",
        "G.name = \"Graph of main buses lines of Montevideo\"\n",
        "print(nx.info(G))\n",
        "\n",
        "\n",
        "# %%\n",
        "df = pd.DataFrame([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n",
        "print(df)\n",
        "A = df.values\n",
        "# G = nx.from_numpy_array(A, parallel_edges=True, create_using=nx.DiGraph())\n",
        "\n",
        "# G = nx.from_pandas_adjacency(df, create_using=nx.Graph)\n",
        "G.name = \"Graph from pandas adjacency matrix\"\n",
        "print(nx.info(G))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}